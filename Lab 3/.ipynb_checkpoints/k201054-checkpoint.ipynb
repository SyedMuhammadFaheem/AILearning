{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the no. of locations: 10\n",
      "[['' '' 'D' '' '' '' '' '' '' '']\n",
      " ['' '' '' '' '' '' '' '' '' '']\n",
      " ['' '' '' '' '' '' '' 'B' '' '']\n",
      " ['' '' '' '' '' '' '' '' 'A' '']\n",
      " ['R' '' '' '' '' '' '' '' '' '']\n",
      " ['' '' '' '' '' '' '' '' '' '']\n",
      " ['' '' 'C' '' '' '' '' '' '' '']\n",
      " ['' '' '' '' '' '' '' '' '' '']\n",
      " ['' '' '' '' '' '' '' '' '' '']\n",
      " ['N' '' '' '' '' '' '' '' '' '']]\n",
      "\n",
      "Euclidean Distance among all given robots:  [4.47213595499958, 6.4031242374328485, 6.4031242374328485, 5.656854249492381, 9.848857801796104]\n"
     ]
    }
   ],
   "source": [
    "#Task1\n",
    "import numpy as np\n",
    "import random as r\n",
    "import math\n",
    "\n",
    "def distance(pos,x2,y2):\n",
    "    return math.sqrt((pos[0] - pos[1])**2 + (x2 - y2)**2)\n",
    "\n",
    "n=int(input(\"Enter the no. of locations: \"))\n",
    "env = np.empty(shape=(n,n),dtype=str)\n",
    "env[4][0]='R'\n",
    "robo_names=['A','B','C','D','N']\n",
    "j=0\n",
    "for i in range(0,5):\n",
    "    x=r.randint(0,n-1)\n",
    "    y=r.randint(0,n-1)\n",
    "    if env[x][y]=='':\n",
    "        env[x][y]=robo_names[j]\n",
    "        j+=1\n",
    "    else:\n",
    "        j-=1\n",
    "print(env)\n",
    "r_pos=[4,0]\n",
    "res=[]\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if env[i][j] in robo_names:\n",
    "            res.append(distance(r_pos,i,j))\n",
    "print(\"\\nEuclidean Distance among all given robots: \",res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Front Camera Distance:  4.184081152725005\n",
      "Left Camera Distance:  9.632746574603349\n",
      "Right Camera Distance:  2.066578567911903\n",
      "Rear Camera Distance:  5.096190847403301 \n",
      "\n",
      "Action taken by front camera: apply_brakes\n",
      "Action taken by left camera: no_action\n",
      "Action taken by right camera: no_action\n",
      "Action taken by rear camera: no_action\n"
     ]
    }
   ],
   "source": [
    "#Task2\n",
    "import random\n",
    "def detectObject(camera_position, object_distance):\n",
    "    if camera_position == \"front\" and object_distance <= 8:\n",
    "        return \"apply_brakes\"\n",
    "    elif camera_position == \"left\" and object_distance <= 2:\n",
    "        return \"move_right\"\n",
    "    elif camera_position == \"right\" and object_distance <= 2:\n",
    "        return \"move_left\"\n",
    "    elif camera_position == \"rear\" and object_distance <= 0.05:\n",
    "        return \"apply_brakes_park\"\n",
    "    else:\n",
    "        return \"no_action\"\n",
    "\n",
    "front_camera_distance = random.uniform(0,10)\n",
    "left_camera_distance = random.uniform(0,10)\n",
    "right_camera_distance = random.uniform(0,10)\n",
    "rear_camera_distance = random.uniform(0,10)\n",
    "\n",
    "print(\"Front Camera Distance: \",front_camera_distance)\n",
    "print(\"Left Camera Distance: \",left_camera_distance)\n",
    "print(\"Right Camera Distance: \",right_camera_distance)\n",
    "print(\"Rear Camera Distance: \",rear_camera_distance,\"\\n\")\n",
    "\n",
    "front_action = detectObject(\"front\", front_camera_distance)\n",
    "left_action = detectObject(\"left\", left_camera_distance)\n",
    "right_action = detectObject(\"right\", right_camera_distance)\n",
    "rear_action = detectObject(\"rear\", rear_camera_distance)\n",
    "\n",
    "print(\"Action taken by front camera:\", front_action)\n",
    "print(\"Action taken by left camera:\", left_action)\n",
    "print(\"Action taken by right camera:\", right_action)\n",
    "print(\"Action taken by rear camera:\", rear_action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature in Celsius:  [33.83031229 22.04883813 35.35906212 23.20254568 26.52147146 42.60121456\n",
      "  3.86065699 20.96003901 36.97359052] \n",
      "\n",
      "Temperature in Fahrenheit:  [ 92.89456213  71.68790864  95.64631181  73.76458223  79.73864862\n",
      " 108.68218621  38.94918257  69.72807021  98.55246293] \n",
      "\n",
      "Average:  81.07154615077087\n"
     ]
    }
   ],
   "source": [
    "#Task3\n",
    "import numpy as np\n",
    "import random\n",
    "temp=[]\n",
    "for i in range(9):\n",
    "    temp.append(random.uniform(-2, 45))\n",
    "temp=np.array(temp)\n",
    "print(\"Temperature in Celsius: \",temp,\"\\n\")\n",
    "temp=temp*1.8+32\n",
    "print(\"Temperature in Fahrenheit: \",temp,\"\\n\")\n",
    "print(\"Average: \",sum(temp)/9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the rows: 10\n",
      "Enter the columns: 5\n",
      "[['C' 'B' 'C' 'D' 'B']\n",
      " ['D' 'D' 'B' 'C' 'D']\n",
      " ['D' 'D' 'B' 'B' 'B']\n",
      " ['B' 'C' 'C' 'B' 'D']\n",
      " ['C' 'B' 'B' 'C' 'D']\n",
      " ['D' 'D' 'D' 'C' 'D']\n",
      " ['C' 'B' 'C' 'C' 'D']\n",
      " ['B' 'C' 'D' 'B' 'C']\n",
      " ['B' 'D' 'D' 'C' 'C']\n",
      " ['D' 'C' 'D' 'D' 'C']] \n",
      "\n",
      "[['C' 'B' 'C' 'D' 'B']\n",
      " ['C' 'D' 'B' 'C' 'D']\n",
      " ['D' 'D' 'B' 'B' 'B']\n",
      " ['B' 'C' 'C' 'B' 'D']\n",
      " ['C' 'B' 'B' 'C' 'D']\n",
      " ['D' 'D' 'D' 'C' 'D']\n",
      " ['C' 'B' 'C' 'C' 'D']\n",
      " ['B' 'C' 'D' 'B' 'C']\n",
      " ['B' 'D' 'D' 'C' 'C']\n",
      " ['D' 'C' 'D' 'D' 'C']] \n",
      "\n",
      "[['C' 'B' 'C' 'D' 'B']\n",
      " ['C' 'D' 'B' 'C' 'D']\n",
      " ['C' 'D' 'B' 'B' 'B']\n",
      " ['B' 'C' 'C' 'B' 'D']\n",
      " ['C' 'B' 'B' 'C' 'D']\n",
      " ['D' 'D' 'D' 'C' 'D']\n",
      " ['C' 'B' 'C' 'C' 'D']\n",
      " ['B' 'C' 'D' 'B' 'C']\n",
      " ['B' 'D' 'D' 'C' 'C']\n",
      " ['D' 'C' 'D' 'D' 'C']] \n",
      "\n",
      "[['C' 'B' 'C' 'D' 'B']\n",
      " ['C' 'D' 'B' 'C' 'D']\n",
      " ['C' 'C' 'B' 'B' 'B']\n",
      " ['B' 'C' 'C' 'B' 'D']\n",
      " ['C' 'B' 'B' 'C' 'D']\n",
      " ['D' 'D' 'D' 'C' 'D']\n",
      " ['C' 'B' 'C' 'C' 'D']\n",
      " ['B' 'C' 'D' 'B' 'C']\n",
      " ['B' 'D' 'D' 'C' 'C']\n",
      " ['D' 'C' 'D' 'D' 'C']] \n",
      "\n",
      "[['C' 'B' 'C' 'D' 'B']\n",
      " ['C' 'C' 'B' 'C' 'D']\n",
      " ['C' 'C' 'B' 'B' 'B']\n",
      " ['B' 'C' 'C' 'B' 'D']\n",
      " ['C' 'B' 'B' 'C' 'D']\n",
      " ['D' 'D' 'D' 'C' 'D']\n",
      " ['C' 'B' 'C' 'C' 'D']\n",
      " ['B' 'C' 'D' 'B' 'C']\n",
      " ['B' 'D' 'D' 'C' 'C']\n",
      " ['D' 'C' 'D' 'D' 'C']] \n",
      "\n",
      "The path taken by the vacuum cleaner: [(0, 0), (1, 0), (2, 0), (2, 1), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "#Task4\n",
    "import numpy as np\n",
    "import random\n",
    "m=int(input(\"Enter the rows: \"))\n",
    "n=int(input(\"Enter the columns: \"))\n",
    "env=np.empty(shape=(m,n),dtype=str)\n",
    "leg=['C','B','D']\n",
    "env[0][0]='D'\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        if env[i][j]=='':\n",
    "            if i==0 and j==0:\n",
    "                continue\n",
    "            env[i][j]=leg[random.randint(0,2)]\n",
    "\n",
    "path=[]\n",
    "i,j=0,0\n",
    "while True:\n",
    "    if env[i][j]=='C':\n",
    "        continue\n",
    "    path.append((i, j))\n",
    "    env[i][j] = \"C\"\n",
    "    print(env,'\\n')\n",
    "    if i>0 and env[i-1][j] == \"D\":\n",
    "        i-=1\n",
    "        continue\n",
    "    if i<n-1 and env[i+1][j] == \"D\":\n",
    "        i+=1\n",
    "        continue\n",
    "    if j>0 and env[i][j-1] == \"D\":\n",
    "        j-=1\n",
    "        continue\n",
    "    if j<m-1 and env[i][j+1] == \"D\":\n",
    "        j+=1\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "print(\"The path taken by the vacuum cleaner:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User's Character is O || Agent's Character is X\n",
      "Enter your move (1-9): 3\n",
      "[['' '' 'O']\n",
      " ['' 'X' '']\n",
      " ['' '' '']] \n",
      "\n",
      "Enter your move (1-9): 9\n",
      "[['' '' 'O']\n",
      " ['' 'X' 'X']\n",
      " ['' '' 'O']] \n",
      "\n",
      "Enter your move (1-9): 1\n",
      "[['O' 'X' 'O']\n",
      " ['' 'X' 'X']\n",
      " ['' '' 'O']] \n",
      "\n",
      "Enter your move (1-9): 7\n",
      "[['O' 'X' 'O']\n",
      " ['X' 'X' 'X']\n",
      " ['O' '' 'O']] \n",
      "\n",
      "X Wins\n"
     ]
    }
   ],
   "source": [
    "#Task5\n",
    "import numpy as np\n",
    "\n",
    "board=np.empty(shape=(3,3),dtype=str)\n",
    "print(\"User's Character is O || Agent's Character is X\")\n",
    "def checkWinner():\n",
    "    global board\n",
    "    for i in range(3):\n",
    "        if board[i][0]==board[i][1] and board[i][1]==board[i][2]:\n",
    "            if board[i][0]=='X':\n",
    "                return 'X'\n",
    "            elif board[i][0]=='O':\n",
    "                return 'O'\n",
    "    for j in range(3):\n",
    "        if board[0][j]==board[1][j] and board[1][j]==board[2][j]:\n",
    "            if board[0][j]=='X':\n",
    "                return 'X'\n",
    "            elif board[0][j]=='O':\n",
    "                return 'O'\n",
    "            \n",
    "    if board[0][0]==board[1][1] and board[1][1]==board[2][2]:\n",
    "        if board[0][0]=='X':\n",
    "            return 'X'\n",
    "        elif board[0][0]=='O':\n",
    "            return 'O'\n",
    "    if board[0][2]==board[1][1] and board[1][1]==board[2][0]:\n",
    "        if board[0][2]=='X':\n",
    "            return 'X'\n",
    "        elif board[0][2]=='O':\n",
    "            return 'O'\n",
    "    if len(list((space for space in np.nditer(board) if space=='')))==0:\n",
    "        return 'Tie'\n",
    "    else:\n",
    "        return 'Continue'\n",
    "        \n",
    "\n",
    "def genScore():\n",
    "    global board\n",
    "    score=0\n",
    "    for i in range(3):\n",
    "        if board[i][0]==board[i][1] and board[i][1]==board[i][2]:\n",
    "            if board[i][0]=='X':\n",
    "                score=10\n",
    "                return score\n",
    "            elif board[i][0]=='O':\n",
    "                score=-10\n",
    "                return score\n",
    "    for j in range(3):\n",
    "        if board[0][j]==board[1][j] and board[1][j]==board[2][j]:\n",
    "            if board[0][j]=='X':\n",
    "                score=10\n",
    "                return score\n",
    "            elif board[0][j]=='O':\n",
    "                score=-10\n",
    "                return score\n",
    "            \n",
    "    if board[0][0]==board[1][1] and board[1][1]==board[2][2]:\n",
    "        if board[0][0]=='X':\n",
    "            score=10\n",
    "            return score\n",
    "        elif board[0][0]=='O':\n",
    "            score=-10\n",
    "            return score\n",
    "    if board[0][2]==board[1][1] and board[1][1]==board[2][0]:\n",
    "        if board[0][2]=='X':\n",
    "            score=10\n",
    "            return score\n",
    "        elif board[0][2]=='O':\n",
    "            score=-10\n",
    "            return score\n",
    "        \n",
    "    return score\n",
    "    \n",
    "    \n",
    "def minimax(depth,maximize):\n",
    "    global board\n",
    "    score=genScore()\n",
    "    \n",
    "    if score==10:\n",
    "        return score\n",
    "    if score==-10:\n",
    "        return score\n",
    "    if len(list((space for space in np.nditer(board) if space=='')))==0:\n",
    "        return 0\n",
    "    if maximize:\n",
    "        bestVal=-1000\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if board[i][j]=='':\n",
    "                    board[i][j]='X'\n",
    "                    bestVal=max(bestVal,minimax(depth+1,not maximize))\n",
    "                    board[i][j]=''\n",
    "        return bestVal\n",
    "    else:\n",
    "        bestVal=1000\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if board[i][j]=='':\n",
    "                    board[i][j]='O'\n",
    "                    bestVal=min(bestVal,minimax(depth+1,not maximize))\n",
    "                    board[i][j]=''\n",
    "        return bestVal\n",
    "        \n",
    "def makeMove():\n",
    "    global board\n",
    "    bestVal=-1000\n",
    "    move=(-1,-1)\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if board[i][j]=='':\n",
    "                board[i][j]='X'\n",
    "                currVal=minimax(0,False)\n",
    "                board[i][j]=''\n",
    "                if bestVal<currVal:\n",
    "                    bestVal=currVal\n",
    "                    move=(i,j)\n",
    "    board[move[0],move[1]]='X'\n",
    "                \n",
    "            \n",
    "    \n",
    "count=0 \n",
    "while True:\n",
    "    global board\n",
    "    index=int(input(\"Enter your move (1-9): \"))\n",
    "    row=int((index-1)/3)\n",
    "    col=(index-1)%3\n",
    "    board[row][col]='O'\n",
    "    if checkWinner()=='O':\n",
    "        print(board,'\\n')\n",
    "        print('O Wins')\n",
    "        break\n",
    "    makeMove()\n",
    "    if checkWinner()=='X':\n",
    "        print(board,'\\n')\n",
    "        print('X Wins')\n",
    "        break\n",
    "    elif checkWinner()=='Tie':\n",
    "        print(board,'\\n')\n",
    "        print('Tie Game')\n",
    "        break\n",
    "    print(board,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAST NU to Karsaz: 15 km\n",
      "FAST NU to Gulshan: 23 km\n",
      "FAST NU to Korangi: 20 km\n",
      "FAST NU to Saddar: 25 km\n"
     ]
    }
   ],
   "source": [
    "#Task6\n",
    "import numpy as np\n",
    "n=5\n",
    "nodes=['FAST NU','Karsaz','Gulshan','Korangi','Saddar']\n",
    "adj_mat=[[0,15,30,20,-1],[15,0,8,10,10],[30,8,0,22,20],[20,10,22,0,10],[-1,10,20,10,0]]\n",
    "dist=[9999 for item in range(5)]\n",
    "dist[0]=0\n",
    "visited=[]\n",
    "u=0\n",
    "\n",
    "while len(visited)<n:\n",
    "    global adj_mat\n",
    "    if u not in visited:\n",
    "        visited.append(u)\n",
    "    for i in range(n):\n",
    "        if adj_mat[u][u]<adj_mat[u][i]+adj_mat[u][u]:\n",
    "            dist[i]=min(adj_mat[u][u]+adj_mat[u][i],dist[i])\n",
    "            adj_mat[i][i]=dist[i]\n",
    "    u+=1\n",
    "source=nodes[0]\n",
    "for item in nodes:\n",
    "    if item != source:\n",
    "        print(str(source) + ' to ' + item + ': ' + str(dist[nodes.index(item)]) + ' km')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7\n",
    "\n",
    "Task 04, which is vacuum cleaning agent, the learning process can be implemented using Q-Learning, where the agent maintains a Q-table that stores the expected cumulative reward for each state-action pair. The Q-table is updated based on the observed reward and the maximum expected cumulative reward for the next state. At the end of the training process, the agent will have learned an optimal policy that allows it to clean the room efficiently, and the path it took can be displayed to show the efficiency of the learning process.\n",
    "\n",
    "\n",
    "Task 05, which is a Tic Tac Toe game, can be transformed into a learning agent by using Reinforcement Learning (RL). The computer agent can learn to play the game optimally by receiving rewards or penalties based on the outcome of each game. For example, the agent can receive a positive reward if it wins the game and a negative reward if it loses. The agent can also receive a reward or penalty based on the moves it makes during the game. By playing multiple games and receiving these rewards, the agent can update its strategy to maximize its rewards over time.\n",
    "\n",
    "\n",
    "Task 06, which is a pathfinding algorithm for minimizing costs on a road trip, can also be transformed into a learning agent using RL. The agent can learn the best route between two nodes by receiving rewards based on the costs of the trip, such as gas and overnight stays. The agent can also receive rewards based on the time it takes to complete the trip and any traffic costs that may arise. Over time, the agent can update its strategy to minimize the overall costs of the trip."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
